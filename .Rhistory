mutate(ip_address = str_extract(detail,ip_pattern))  # regex extractip addresses
# REGEX extract ip address
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
filter(nchar(date) >2 | date == "initialized")  %>% #remove order numbers so only have rows with a date
mutate(ip_address = str_extract(detail,ip_pattern))  # regex extractip addresses
# REGEX extract ip address
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(ip_address = str_extract(detail,ip_pattern)) %>% # regex extractip addresses
filter(date != "initialized")
view(log_file)
view(log_file)
log_file$date[31]
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(ip_address = str_extract(detail,ip_pattern)) %>% # regex extractip addresses
filter(date != "initi")
# REGEX extract ip address
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(ip_address = str_extract(detail,ip_pattern))  # regex extractip addresses
# filter(date != "initi")
# REGEX extract ip address
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
filter(nchar(date) >2 | date != "initi")  %>% #remove order numbers so only have rows with a date
mutate(ip_address = str_extract(detail,ip_pattern))  # regex extractip addresses
# REGEX extract ip address
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
mutate(date = as.Date(date, "%d/%m")) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(ip_address = str_extract(detail,ip_pattern)) %>% # regex extractip addresses
filter(date != "initi")
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
# mutate(date = as.Date(date, "%d/%m")) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(ip_address = str_extract(detail,ip_pattern)) %>% # regex extractip addresses
filter(date != "initi")
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
mutate(date = as.Date(date, "%d.%m")) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(ip_address = str_extract(detail,ip_pattern)) %>% # regex extractip addresses
filter(date != "initi")
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
filter(date != "initi") %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(date = as.Date(date, "%d.%m")) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
mutate(ip_address = str_extract(detail,ip_pattern)) # regex extractip addresses
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
filter(date != "initi") %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(date = as.Date(date, "%d/%m")) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
mutate(ip_address = str_extract(detail,ip_pattern)) # regex extractip addresses
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
filter(date != "initi") %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(date = as.date(date, "%d/%m")) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
mutate(ip_address = str_extract(detail,ip_pattern)) # regex extractip addresses
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
filter(date != "initi") %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(date = as.Date(date)) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
mutate(ip_address = str_extract(detail,ip_pattern)) # regex extractip addresses
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
filter(date != "initi") %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(date = as.Date(as,numeric(date)) ) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
mutate(ip_address = str_extract(detail,ip_pattern)) # regex extractip addresses
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
filter(date != "initi") %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(date = as.Date(as.numeric(date)) ) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
mutate(ip_address = str_extract(detail,ip_pattern)) # regex extractip addresses
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
iles
library(readr)
library(tidyverse)
library(stringr)
library(lubridate)
#reasing in as a text
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
filter(date != "initi") %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(date = as.Date(as.numeric(date, "%m/%d")) ) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
mutate(ip_address = str_extract(detail,ip_pattern)) # regex extractip addresses
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
filter(date != "initi") %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(date = as.Date(date,
format = "%m/%d/%y") ) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
mutate(ip_address = str_extract(detail,ip_pattern)) # regex extractip addresses
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
filter(date != "initi") %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(date = as.Date(date,
format = "%m/%d") ) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
mutate(ip_address = str_extract(detail,ip_pattern)) # regex extractip addresses
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
nchar(log_file$time[3])
view(log_file)
view(log_file)
parse_date_time(log_file$time, "hms")
hms(log_file$time)
library(chron)
install.packages("chron")
chron(log_file$time)
chron::chron(log_file$time)
chron::chron(times=log_file$time)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
filter(date != "initi") %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(date = as.Date(date,
format = "%m/%d") ) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(time = chron::chron(times=$time)) %>%
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
mutate(ip_address = str_extract(detail,ip_pattern)) # regex extractip addresses
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
hms(log_file$time)
nchar(log_file$time[3])
view(log_file)
log_file <- read_tsv("data/log_file.log") %>%
janitor::clean_names()
class(log_file$log)
ip_pattern <- "[0-9]+.[0-9]+.[0-9]+.[0-9]"
log_file <- log_file %>%
mutate(date = str_replace_all(str_sub(log, 1, 5)," ", "")) %>% # extract date and remove white space
filter(date != "initi") %>%
filter(nchar(date) >2)  %>% #remove order numbers so only have rows with a date
mutate(date = as.Date(date,
format = "%m/%d") ) %>%
mutate(time = str_replace_all(str_sub(log, 6, 15)," ", "")) %>% # extract time and remove white space
mutate(time = chron::chron(times=time)) %>%
mutate(info = str_sub(log, 16, 22)) %>%
mutate(detail = str_sub(log, 23, -1)) %>%
mutate(ip_address = str_extract(detail,ip_pattern)) # regex extractip addresses
# filter warning and ... if failed
# convert to date and time
# try other log files
# count common words
# highlight fact could visualize failures, ip address numbers
# create git repo
hms(log_file$time)
nchar(log_file$time[3])
view(log_file)
class(log_file$time)
View(log_file)
log_warnings <- log_file %>%
filter(info == "WARNING")
log_warnings
ip_check <- log_file %>%
drop_na(ip_address)
View(ip_check)
ip_activity_count <- ip_check %>%
group_by(ip_address) %>%
summarise(ip_count = n(ip_address))
ip_activity_count <- ip_check %>%
group_by(ip_address) %>%
summarise(ip_count = nunique(ip_address))
ip_activity_count <- ip_check %>%
group_by(ip_address) %>%
summarise(ip_count = count(ip_address))
ip_activity_count <- ip_check %>%
group_by(ip_address)
View(ip_activity_count)
ip_activity_count <- ip_check %>%
group_by(ip_address) %>%
summarise(ip_count = nrow(ip_address))
View(ip_activity_count)
ip_activity_count <- ip_check %>%
group_by(ip_address) %>%
summarise(ip_count = n(ip_address))
ip_activity_count <- ip_check %>%
group_by(ip_address) %>%
summarise(n = n(ip_address))
unique(ip_check$ip_address)
ip_activity_count <- ip_check %>%
group_by(ip_address) %>%
summarise(n = n())
ip_activity_count
View(ip_activity_count)
ip_activity_count <- ip_check %>%
group_by(ip_address, date) %>%
summarise(n = n())
View(ip_activity_count)
colour_feelings <- list(
blue   = c("Sad", "Calm"),
red    = c("Angry", "Energetic", "Warm"),
green  = c("Calm", "Nature"),
yellow = c("Happy", "Warm", "Sunny")
)
map(.x = colour_feelings, .f = length)
map(.x = colour_feelings, .f = nchar())
map(.x = colour_feelings, .f = nchar)
library(repurrrsive)
#map on a list
install.packages("repurrrsive")
library(purrr)
library(repurrrsive)
#map on a list
colour_feelings <- list(
blue   = c("Sad", "Calm"),
red    = c("Angry", "Energetic", "Warm"),
green  = c("Calm", "Nature"),
yellow = c("Happy", "Warm", "Sunny")
)
map(.x = colour_feelings, .f = nchar)
dat <- got_chars
View(dat)
map(dat, "name")
map(dat, pluck("name"))
map(dat, 3)
View(dat)
class(dat)
x <- map_dfr(dat,`[`, c("name", "gender", "culture", "aliases", "allegiances"))
dat_m <- dat %>% {
tibble(
name = map_chr(., "name"),
gender = map_chr(., "gender"),
culture = map_chr(., "culture"),
aliases = map(., "aliases"),
allegiances = map(., "allegiances")
)}
map(dat_m, length)
View(dat_m)
map(dat_m, nchar)
dead_or_alive <- function(x){
ifelse(x[["alive"]], paste(x[["name"]], "is alive!"),
paste(x[["name"]], "is dead :("))
}
map_chr(dat, dead_or_alive)
blue <- list(
translation = "gorm",
feelings    = c("Sad", "Calm"),
primary     = "Yes",
wavelength  = 470
)
map_if(.x = blue, .p = is.character, .f = nchar)
map(blue, possibly(round, "Not a number"))
